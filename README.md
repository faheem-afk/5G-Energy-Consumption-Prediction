Thanks for sharing the updated visual of your folder structure! Based on it, hereâ€™s the updated and complete README.md content with the correct folder and file explanations incorporated:

â¸»

ğŸ“¡ 5G Energy Consumption Prediction

This repository contains the complete implementation of a machine learning-based system for predicting hourly energy consumption of 5G base stations. It is designed to help telecom operators anticipate power demands and improve energy efficiency through intelligent, data-driven modeling.

â¸»

ğŸ¯ Research Aim and Objectives

Aim:
To develop a reliable ML-based model capable of accurately predicting the energy consumption (in kWh) of 5G base stations. The goal is to support network operators in improving their energy-saving strategies.

Objectives:
	â€¢	ğŸ“š Review ML methods applied to energy prediction in 5G networks.
	â€¢	ğŸ§ª Select an appropriate Data Science methodology.
	â€¢	ğŸ“¥ Gather and process datasets with features like configuration, traffic load, and energy usage.
	â€¢	ğŸ§  Design, train, and evaluate multiple ML models (MLP, CNN, LSTM, GRU).
	â€¢	ğŸŒ Test models on unseen base stations to ensure generalization.
	â€¢	ğŸ“Š Analyze results and recommend strategies based on performance.

â¸»

â— Problem Analysis Summary
	â€¢	Time-Dependency: Energy usage depends on lagged features such as traffic, configuration, and past energy levels.
	â€¢	Data Leakage Risk: If base stations appear in both train/validation sets, the model might memorize rather than generalize.
	â€¢	Overfitting: Inflated performance on validation sets may not transfer to new stations.
	â€¢	Imbalanced Data: Overrepresented base stations can bias the model.
	â€¢	Model Selection: No universally optimal architecture; various deep models tested.
	â€¢	Hyperparameter Tuning: Manual tuning is error-prone; automated strategies are used (Optuna, TPE, CMA-ES).

â¸»

ğŸ§  Design Highlights
	â€¢	âœ… Temporal features engineered: via lagging traffic, energy, and settings.
	â€¢	âœ… Hybrid Deep Models: CNN for short-term pattern extraction + LSTM/GRU for temporal learning.
	â€¢	âœ… GroupKFold Strategy: Avoids leakage by keeping base stations exclusive to each fold.
	â€¢	âœ… Smart Hyperparameter Optimization: Done using Optuna (TPE & CMA-ES samplers).

â¸»

ğŸ“‚ Folder Structure Overview

ğŸ“ 5g-project-data/       # Raw base station, config, energy files (CSV)
ğŸ“ data/
  â””â”€â”€ preprocessed_data/ # Train/test splits as parquet
ğŸ“ artifacts/             # Trained model files (GRU, LSTM, RNN)
ğŸ“ logs/                  # Training logs
ğŸ“ results/               # Per-model MAE results
ğŸ“ Training-specs/        # Training durations and device usage logs
ğŸ“ feature-imp/           # SHAP feature impact visualizations
ğŸ“ hypothesis_tests/      # One-sided t-test results for model significance
ğŸ“ comparison-graphs/     # MAE comparison graphs


â¸»

ğŸ§¾ Script Overview

Script	Purpose
main.py	ğŸš€ Entry point: Runs the full pipeline
data_ingestion.py	ğŸ“¥ Converts raw CSVs to parquet format
data_preprocessing.py	ğŸ§¹ Cleans data, adds lags, applies smoothing filters
training_prediction.py	ğŸ§  Trains models (GRU, LSTM, etc.) using GroupKFold
evaluation_comparison.py	ğŸ“Š Compares trained models with the baseline
feature_importance_shap.py	ğŸ” Visualizes SHAP values for feature explanation
hypothesis_testing.py	ğŸ“ˆ Runs 1-sample t-test (MAE < 1.5) and outputs significance
Models.py	ğŸ—ï¸ Contains definitions for MLP, CNN, LSTM, GRU
settings.py	âš™ï¸ Global paths and constant configurations
variables.yaml	ğŸ“‘ Hyperparameter ranges and training variables
utils.py	ğŸ§° Helper functions
logger.py	ğŸ“ Logging utility for experiment tracking
pipeline.py	ğŸ”„ Utility for chaining major steps together


â¸»

ğŸ How to Run
	1.	Clone the repository

git clone https://github.com/yourusername/5g-energy-prediction.git
cd 5g-energy-prediction


	2.	Install dependencies

pip install -r requirements.txt


	3.	Run the pipeline

python main.py


	4.	Outputs will be saved to:
	â€¢	results/ â€“ MAE scores per model
	â€¢	artifacts/ â€“ Trained model binaries
	â€¢	feature-imp/ â€“ SHAP plots
	â€¢	hypothesis_tests/ â€“ p-value analysis
	â€¢	Training-specs/ â€“ Time taken per fold/device info

â¸»

ğŸ”¬ Requirements

Listed in requirements.txt:

matplotlib==3.6.3
numpy==1.23.5
pandas==1.5.3
PyYAML==6.0.2
scikit_learn==1.7.0
scipy==1.9.3
seaborn==0.13.2
shap==0.48.0
tensorflow==2.18.0
torch==2.6.0
tqdm==4.64.1


â¸»

ğŸ“ˆ Sample Output Visuals
	â€¢	MAE Comparison between models
	â€¢	SHAP plots showing feature impact
	â€¢	One-sided t-test JSON verdicts
	â€¢	Training time summary logs

â¸»

ğŸ“¬ Contact

For queries or feedback, reach out via GitHub or email the project author.

â¸»

Let me know if you want this README exported as a file or tailored for a specific GitHub theme (e.g. dark/light markdown, badges, license, contribution instructions, etc.).
